{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "3_aug_ewc.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqcMq7lAAV6J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pwnzFjNuG7M",
        "outputId": "5a383b72-b413-4f55-ec2f-a4f4cd7279e7"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(1);\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ktRhuKG6L5G"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lWEkBcT6Mwf",
        "outputId": "906b3838-7bc5-4366-e73b-fc934d607fa0"
      },
      "source": [
        "!git clone https://github.com/ContinualAI/colab.git continualai/colab\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'continualai/colab' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_RVEmQp6S4O",
        "outputId": "54028b7c-e70b-49be-c032-184c1ab4b2c7"
      },
      "source": [
        "from continualai.colab.scripts import mnist\n",
        "mnist.init()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E17A1lhb6jvu"
      },
      "source": [
        "x_train, t_train, x_test, t_test = mnist.load()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2IseMhk6nP1"
      },
      "source": [
        "use_cuda = True\n",
        "\n",
        "use_cuda = use_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAjU04tW61IJ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddfRitX643T"
      },
      "source": [
        "def train(model, device, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "\n",
        "def test(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_test)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return 100. * correct / len(t_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeaG_QLBWPmF",
        "outputId": "425423a0-b78e-4780-a4ea-7c224b3b81ab"
      },
      "source": [
        "len(t_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UYTvLSY7E5f"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJbe9Y5G7Sk-",
        "outputId": "55eacd80-f680-42cb-bebf-f5f3f50d2509"
      },
      "source": [
        "for epoch in range(1, 3):\n",
        "  train(model, device, x_train, t_train, optimizer, epoch)\n",
        "  test(model, device, x_test, t_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 0.762133\n",
            "Test set: Average loss: 0.0013, Accuracy: 9018/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.488891\n",
            "Test set: Average loss: 0.0007, Accuracy: 9440/10000 (94%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-U4kOxC7UCo"
      },
      "source": [
        "def permute_mnist(mnist, seed):\n",
        "    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    print(\"starting permutation...\")\n",
        "    h = w = 28\n",
        "    perm_inds = list(range(h*w))\n",
        "    np.random.shuffle(perm_inds)\n",
        "    # print(perm_inds)\n",
        "    perm_mnist = []\n",
        "    for set in mnist:\n",
        "        num_img = set.shape[0]\n",
        "        flat_set = set.reshape(num_img, w * h)\n",
        "        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n",
        "    print(\"done.\")\n",
        "    return perm_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJs6N7097jom",
        "outputId": "467a6abb-eb34-4c0c-b9cf-60860d4ef9eb"
      },
      "source": [
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2onyqK4e7oQ-",
        "outputId": "5cce1ba0-c3ce-4f55-b0c5-824b621696b0"
      },
      "source": [
        "print(\"Testing on the first task:\")\n",
        "test(model, device, x_test, t_test)\n",
        "\n",
        "print(\"Testing on the second task:\")\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0007, Accuracy: 9440/10000 (94%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0108, Accuracy: 1037/10000 (10%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKDUGFTe7zVN",
        "outputId": "311911d0-d919-418b-eeda-d3784eac1970"
      },
      "source": [
        "for epoch in range(1, 3):\n",
        "  train(model, device, x_train2, t_train, optimizer, epoch)\n",
        "  test(model, device, x_test2, t_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 1.516058\n",
            "Test set: Average loss: 0.0033, Accuracy: 7315/10000 (73%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.188572\n",
            "Test set: Average loss: 0.0022, Accuracy: 8199/10000 (82%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcY85Yr475Wp",
        "outputId": "3be0aad1-33f9-480a-d91e-64661ccdcc3d"
      },
      "source": [
        "\n",
        "print(\"Testing on the first task:\")\n",
        "test(model, device, x_test, t_test)\n",
        "\n",
        "print(\"Testing on the second task:\")\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0199, Accuracy: 2384/10000 (24%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0022, Accuracy: 8199/10000 (82%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q45UV_h8JYq",
        "outputId": "1bbf0b5f-e441-4d78-eec2-ed8997471bc0"
      },
      "source": [
        "# task 1\n",
        "task_1 = [(x_train, t_train), (x_test, t_test)]\n",
        "\n",
        "# task 2\n",
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n",
        "task_2 = [(x_train2, t_train), (x_test2, t_test)]\n",
        "\n",
        "# task 3\n",
        "x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n",
        "task_3 = [(x_train3, t_train), (x_test3, t_test)]\n",
        "\n",
        "# task list\n",
        "tasks = [task_1, task_2, task_3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecYJ4YIlPEpC",
        "outputId": "c707afe8-0054-4492-e57f-1408cd265b10"
      },
      "source": [
        "print(task_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.18039216],\n",
            "         [0.50980395, 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.7764706 , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.99215686],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.83137256, ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.09411765],\n",
            "         [0.5803922 , 0.98039216, 0.        , ..., 0.9764706 ,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.57254905, 0.        ],\n",
            "         [0.76862746, 0.9882353 , 0.9882353 , ..., 0.        ,\n",
            "          0.        , 0.5137255 ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.74509805, 0.        ],\n",
            "         [0.        , 0.30980393, 0.        , ..., 0.        ,\n",
            "          0.        , 0.1882353 ],\n",
            "         [0.        , 0.63529414, 0.        , ..., 0.02745098,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.99607843],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.18431373, 0.        ],\n",
            "         [0.        , 0.7176471 , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.99607843, 0.        , ..., 0.6627451 ,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.07843138, 0.        , 0.14117648, ..., 0.        ,\n",
            "          0.        , 0.62352943],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.99215686, ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.6784314 , 0.        , ..., 0.99215686,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.03137255, 0.        , ..., 0.        ,\n",
            "          0.6627451 , 0.        ],\n",
            "         [0.        , 0.94509804, 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.94509804, 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.32156864],\n",
            "         [0.08627451, 0.69803923, 0.        , ..., 0.03529412,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.99607843, ..., 0.        ,\n",
            "          0.07450981, 0.        ],\n",
            "         [0.        , 0.99607843, 0.        , ..., 0.02745098,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.75686276, ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.36078432, 0.        , ..., 0.        ,\n",
            "          0.        , 0.07450981],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ]]]], dtype=float32), array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)), (array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.29411766],\n",
            "         [0.9843137 , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.3019608 , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.99607843, 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.07450981, 0.        , 0.        , ..., 0.7137255 ,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.99215686, ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.5529412 , ..., 0.        ,\n",
            "          0.99215686, 0.        ],\n",
            "         [0.99215686, 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.5647059 ,\n",
            "          0.        , 0.99215686],\n",
            "         [0.07843138, 0.01960784, 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.5568628 ],\n",
            "         [0.        , 0.        , 0.09411765, ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.3019608 ,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.99607843,\n",
            "          0.        , 0.        ],\n",
            "         [0.99607843, 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.99607843],\n",
            "         [0.99607843, 0.        , 0.78039217, ..., 0.        ,\n",
            "          0.        , 0.        ],\n",
            "         [0.03137255, 0.        , 0.99607843, ..., 0.99607843,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.99607843, 0.        ],\n",
            "         [0.        , 0.99607843, 0.        , ..., 0.04313726,\n",
            "          0.        , 0.05490196],\n",
            "         [0.99607843, 0.        , 0.        , ..., 0.04313726,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.99607843],\n",
            "         [0.99607843, 0.        , 0.        , ..., 0.        ,\n",
            "          0.99607843, 0.        ],\n",
            "         [0.6784314 , 0.        , 0.15294118, ..., 0.18431373,\n",
            "          0.        , 0.        ],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.01960784, 0.        ],\n",
            "         [0.        , 0.4509804 , 0.        , ..., 0.99607843,\n",
            "          0.        , 0.8627451 ],\n",
            "         [0.23529412, 0.        , 0.        , ..., 0.49411765,\n",
            "          0.        , 0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.3647059 ],\n",
            "         [0.3372549 , 0.83137256, 0.99215686, ..., 0.        ,\n",
            "          0.99215686, 0.        ],\n",
            "         [0.5176471 , 0.02745098, 0.99607843, ..., 0.        ,\n",
            "          0.        , 0.23529412],\n",
            "         ...,\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.99215686, 0.        ],\n",
            "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
            "          0.        , 0.99215686],\n",
            "         [0.99215686, 0.99215686, 0.        , ..., 0.03529412,\n",
            "          0.01960784, 0.        ]]]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iibtwq8d8ZSf"
      },
      "source": [
        "fisher_dict = {}\n",
        "optpar_dict = {}\n",
        "ewc_lambda = .8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUQeDX4O8f5D"
      },
      "source": [
        "def on_task_update(task_id, x_mem, t_mem):\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # accumulating gradients\n",
        "  for start in range(0, len(t_mem)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "\n",
        "  fisher_dict[task_id] = {}\n",
        "  optpar_dict[task_id] = {}\n",
        "\n",
        "  # gradients accumulated can be used to calculate fisher\n",
        "  for name, param in model.named_parameters():\n",
        "    \n",
        "    optpar_dict[task_id][name] = param.data.clone()\n",
        "    fisher_dict[task_id][name] = param.grad.data.clone().pow(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgl2sh4l8ldE"
      },
      "source": [
        "def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      \n",
        "      ### magic here! :-)\n",
        "      for task in range(task_id):\n",
        "        for name, param in model.named_parameters():\n",
        "          fisher = fisher_dict[task][name]\n",
        "          optpar = optpar_dict[task][name]\n",
        "          loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_itETqi8q1p",
        "outputId": "3f38368f-110c-4dd0-cd1d-1971c2d47256"
      },
      "source": [
        "ewc_accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  for epoch in range(1, 3):\n",
        "    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n",
        "  on_task_update(id, x_train, t_train)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc\n",
        "   \n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  ewc_accs.append(avg_acc / 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.695245\n",
            "Train Epoch: 2 \tLoss: 0.399131\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0005, Accuracy: 9575/10000 (96%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0116, Accuracy: 564/10000 (6%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0102, Accuracy: 1049/10000 (10%)\n",
            "\n",
            "Avg acc:  37.29333333333333\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.975686\n",
            "Train Epoch: 2 \tLoss: 1.523340\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0013, Accuracy: 9020/10000 (90%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0033, Accuracy: 7683/10000 (77%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0110, Accuracy: 1016/10000 (10%)\n",
            "\n",
            "Avg acc:  59.06333333333333\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.350289\n",
            "Train Epoch: 2 \tLoss: 2.050240\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0014, Accuracy: 8942/10000 (89%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0057, Accuracy: 5056/10000 (51%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0041, Accuracy: 7100/10000 (71%)\n",
            "\n",
            "Avg acc:  70.32666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}